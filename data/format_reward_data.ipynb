{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/fish/octupus-tool-call/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "import datasets\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since Skywork/Skywork-Reward-Preference-80K-v0.2 couldn't be found on the Hugging Face Hub (offline mode is enabled).\n",
      "Found the latest cached dataset configuration 'default' at /Users/admin/.cache/huggingface/datasets/Skywork___skywork-reward-preference-80_k-v0.2/default/0.0.0/9757870d81894c90216e92536bad48f41475d5d0 (last modified on Wed Dec 11 15:55:17 2024).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected', 'source'],\n",
       "    num_rows: 77016\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds = datasets.load_dataset(\"Skywork/Skywork-Reward-Preference-80K-v0.2\")[\"train\"]\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=10): 100%|██████████| 77016/77016 [00:01<00:00, 59711.02 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['chosen', 'rejected', 'source', 'conversation'],\n",
       "    num_rows: 77016\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_func(example):\n",
    "    ret = {}\n",
    "    ret[\"conversation\"] = example[\"chosen\"][:-1]\n",
    "    ret[\"chosen\"] = example[\"chosen\"][-1]\n",
    "    ret[\"rejected\"] = example[\"rejected\"][-1]\n",
    "    return ret\n",
    "\n",
    "map_ds = ds.map(map_func, num_proc=10)\n",
    "map_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chosen': {'content': 'The revised code is quite close to the solution. I made some changes and added comments for clarity:\\n\\n```python\\nfrom Bio import SeqIO\\nfrom collections import defaultdict\\n\\nmegascaffold_dict = defaultdict(list)\\nfor record in SeqIO.parse(\"megascaffolds.fasta\", \"fasta\"):\\n    megascaffold_dict[record.id] = record.seq\\n\\ngene_sequences = defaultdict(list)\\nwith open(\"megascaffold_coordinates.gff\") as f:\\n    contig = \\'\\'\\n    previous_end = 0\\n    for line in f:\\n        values = line.strip().split(\"\\\\t\")\\n        curr_contig = values[0]\\n        start = int(values[3]) - 1\\n        end = int(values[4])\\n        gene_id = values[8].split(\"=\")[1]\\n        \\n        # If we\\'re on a new contig, handle the last sequence on the previous contig\\n        if contig != curr_contig:\\n            if previous_end != 0:\\n                last_gene_seq = megascaffold_dict[contig][previous_end:]\\n                gene_sequences[contig].append((f\"{contig}_{len(gene_sequences[contig])}\", last_gene_seq))\\n            contig = curr_contig\\n            previous_end = 0\\n            \\n            # If the first gene on the new contig doesn\\'t start at the beginning, \\n            # add the initial sequence to the list\\n            if start != 0:\\n                first_gene_seq = megascaffold_dict[contig][0:start]\\n                gene_sequences[contig].append((f\"{contig}_{len(gene_sequences[contig])}\", first_gene_seq))\\n\\n        # If there\\'s a gap between the current gene and the previous one, \\n        # add the intergenic sequence to the list\\n        elif previous_end != 0 and previous_end != end:\\n            if start > previous_end + 1:\\n                intergene_seq = megascaffold_dict[contig][previous_end + 1:start]\\n                gene_sequences[contig].append((f\"{contig}_{len(gene_sequences[contig])}\", intergene_seq))\\n            elif start < previous_end + 1:\\n                print(curr_contig, values[2], start, end, \"Error condition\")\\n\\n        # Add the current gene to the list\\n        gene_seq = megascaffold_dict[contig][start:end]\\n        gene_sequences[contig].append((gene_id, gene_seq))\\n        previous_end = end\\n\\n    # Add the last sequence on the last contig\\n    if previous_end != len(megascaffold_dict[curr_contig]):\\n        last_gene_seq = megascaffold_dict[curr_contig][previous_end:]\\n        gene_sequences[curr_contig].append((f\"{curr_contig}_{len(gene_sequences[curr_contig])}\", last_gene_seq))\\n\\nseq_count = 1\\nfor contig, values in gene_sequences.items():\\n    for index, (gene_id, sequence) in enumerate(values):\\n        with open(f\"sequence_{seq_count}.fasta\", \"w\") as f:\\n            f.write(f\">{gene_id}\\\\n{sequence}\\\\n\")\\n        seq_count += 1\\n```\\n\\nThe revised code handles the following scenarios:\\n\\n* When switching to a new contig, it adds the last sequence on the previous contig to the list.\\n* If the first gene on a new contig doesn\\'t start at the beginning of the contig, it adds the initial sequence to the list.\\n* If there are gaps between genes, it adds the intergenic sequences to the list.\\n* After processing all genes, it adds the last sequence on the last contig to the list.\\n\\nNote that I\\'ve kept the same logic as your revised code, but added comments for clarity and made some minor formatting changes for readability.',\n",
       "  'role': 'assistant'},\n",
       " 'rejected': {'content': 'continuation of the code provided by the stackoverflow user:\\n```python\\nlen(gene_sequences[curr_contig])}\", last_gene_seq))\\n\\nseq_count = 1\\nfor contig, values in gene_sequences.items():\\n    for index, (gene_id, sequence) in enumerate(values):\\n        with open(f\"sequence_{seq_count}.fasta\", \"w\") as f:\\n            f.write(f\">{gene_id}\\\\n{sequence}\\\\n\")\\n        seq_count += 1\\n```\\nPlease note that this code makes some assumptions, and it may not handle all types of GFF file variations. You should try it out and see how it works for your specific use case.\\n\\n## Explanation\\nThe above code takes a bit more complex approach, but the overall idea is similar to your attempt of keeping track of previous gene end. Here are the key points:\\n\\n* The code processes the GFF file line by line, and for each line it extracts information such as contig, gene start/end coordinates, gene ID, etc.\\n* When switching between contigs, the code checks whether there was a last gene sequence that hasn\\'t been processed yet (i.e., a leftover from the previous contig). If so, it creates a new sequence for the leftover and appends it to the current contig\\'s list of sequences.\\n* The code also checks whether the first sequence in a new contig starts at position 0. If not, it creates a new \"first\" gene sequence and stores it in the gene_sequences dictionary.\\n* Once the code has finished processing a contig, it makes sure to append any leftover gene sequences to the end of the sequence list.\\n* When dealing with overlapping genes, the code checks if the previous end is smaller than the new start. If TRUE, then the code prints out the line with an \"Error condition\" message.\\n\\nOverall, the code attempts to handle various scenarios where gene sequences might have unequal lengths, intergenic regions, or even overlapping regions between adjacent genes. \\n\\nHopefully, this helps answer your question! Let me know if you need something else.\\n\\nAnd here is an article on the same topic:\\n\\n## Breaking Down Megascaffolds Using Gene Coordinates \\n\\nGenomic studies often involve working with large sequences known as megascaffolds. These long sequences contain multiple genes, intergenic regions, and other genetic information. Breaking down these scaffolds into individual gene sequences can provide useful insights into the organization and structure of chromosomes. In this article, we will discuss how to split megascaffolds based on gene coordinates obtained from a GFF file. We will also show some Python code to automate this task.\\n\\n### GFF Format and Megascaffold Files\\n\\nThe GFF format is commonly used to store annotation data along with genomic sequences. A typical GFF record looks like this:\\n\\n```\\nchr1    refGene    exon    1    56    .    -    .    name=NM_001072\\n```\\n\\nHere, the first column specifies the chromosome number (or megascaffold ID), followed by the source of the feature (refGene). The third field indicates the type of the feature (exon), while the next two fields define its start and end coordinates, respectively. The orientation of the feature is denoted by \\'-\\' or \\'+\\', and the \\'name\\' attribute contains additional information such as the Name of the feature.\\n\\nA common way to organize large genomic sequences is through the use of \"megascaffolds\". A megascaffold consists of many smaller sequences joined together into one longer one. The primary purpose of these megascaffolds is to reduce the complexity of genome assemblies. However, when working with such large sequences, it becomes essential to break them down into manageable chunks. This is especially important in cases where researchers want to analyze specific genes or compare different regions of the genome.\\n\\n### Breaking Down Megascaffolds With Python\\n\\nTo illustrate how to decompose megascaffolds using gene coordinates, let us consider a hypothetical dataset consisting of several megascaffold files and a corresponding GFF file containing annotations for each gene. Our goal is to create separate FASTA files for every gene present in the GFF file, ordered according to their appearance on the megascaffolds.\\n\\nWe can achieve this task using the following steps:\\n\\n1. Read in the fasta files and store them in a dictionary\\n2. Parse the GFF file and obtain the gene coordinates\\n3. Group the coordinates according to their megascaffold IDs\\n4. Use a sliding window approach to iterate through each group of coordinates, updating the sequence headers and writing out the sequences to files\\n\\nHere is some sample python code implementing this strategy:\\n\\n```python\\nimport os\\nfrom Bio import SeqIO\\nfrom collections import defaultdict\\n\\n\\n# Step 1: Read in the fasta files and store them in a dictionary\\nmegascaffold_dict = {}\\nfor root, dirs, files in os.walk(\"/path/to/fasta/files\"):\\n    for file in files:\\n        if file.endswith(\".fa\"):\\n            with open(os.path.join(root, file)) as f:\\n                seqs = list(SeqIO.parse(f, \"fasta\"))\\n                megascaffold_dict[file] = seqs[0]\\n\\n# Step 2: Parse the GFF file and obtain the gene coordinates\\ngene_coords = []\\nwith open(\"/path/to/gff\", \\'r\\') as f:\\n    for line in f:\\n        values = line.strip().split(\\'\\\\t\\')\\n        coord = (values[0], int(values[3]) - 1, int(values[4]))\\n        gene_coords.append(coord)\\n\\n# Step 3: Group the coordinates according to their megascaffold IDs\\ncoord_groups = defaultdict(list)\\nfor coord in gene_coords:\\n    coord',\n",
       "  'role': 'assistant'},\n",
       " 'source': 'magpie_ultra',\n",
       " 'conversation': [{'content': 'Python code to break down contigs from a megascaffold fasta file into individual fasta files. \\n\\nHere is the format of the fasta file:\\n\\n```\\n>megascaffold_1\\nACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\\nACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\\n>megascaffold_2\\nACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\\nACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\\n```\\n\\n.. and so on.\\n\\nAnd here is the gff file corresponding to that fasta file\\n\\n```\\nmegascaffold_1  .  gene  1  500  .  +  .  ID=gene1\\nmegascaffold_1  .  gene  501  1000 .  +  .  ID=gene2\\nmegascaffold_1  .  gene  1001 1500 .  +  .  ID=gene3\\nmegascaffold_2  .  gene  1  500  .  +  .  ID=gene4\\nmegascaffold_2  .  gene  501  1000 .  +  .  ID=gene5\\nmegascaffold_2  .  gene  1001 1500 .  +  .  ID=gene6\\n```\\n\\nI would like to break down the megascaffods into individual fasta file, using information from GFF file. That is, break them whenever there is intergenic region. That means that the breakpoints are 1 coordinate after every gene end until the start of next gene.\\n\\nHere are the desired files:\\n\\nfile1.fasta\\n\\n```\\n>gene1\\nACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\\n```\\n\\nfile2.fasta\\n\\n```\\n>gene2\\nACGTACGTACGTACGTACGTACGTACGTACGTACGTACGT\\n```\\n\\n... and so on. There will as many file as are the genes.\\n\\nHere is my current code:\\n\\n```python\\nfrom Bio import SeqIO\\nfrom collections import defaultdict\\n\\nmegascaffold_dict = defaultdict(list)\\nfor record in SeqIO.parse(\"megascaffolds.fasta\", \"fasta\"):\\n    megascaffold_dict[record.id] = record.seq\\n\\ngene_sequences = defaultdict(list)\\nwith open(\"megascaffold_coordinates.gff\") as f:\\n    for line in f:\\n        values = line.strip().split(\"\\\\t\")\\n        contig = values[0]\\n        start = int(values[3]) - 1\\n        end = int(values[4])\\n        gene_id = values[8].split(\"=\")[1]\\n        gene_seq = megascaffold_dict[contig][start:end]\\n        gene_sequences[gene_id] = gene_seq\\n\\nfor index, (gene_id, sequence) in enumerate(gene_sequences.items()):\\n    with open(f\"gene_sequences_{index+1}.fasta\", \"w\") as f:\\n        f.write(f\">{gene_id}\\\\n\")\\n        f.write(f\"{sequence}\\\\n\")\\n```\\n\\nThis code appears to be working but the issue is that it relies on gene_id from GFF file for sequence identification which are not ordered. So, the gene_sequences fasta files that I am getting are not correctly ordered in terms of their occurance on the megascaffolds.\\n\\nAlso, in the current code, I am not considering the breakpoints between genes. That is, the code simply retrieves the sequences according the gene coordinates in GFF file. But I would like to break the megascaffolds whenever there are breaks between genes.\\n\\nIs there any more elegant approach to do this. Also, I would like to keep the sequences in the files correctly ordered as they are in the megascaffolds.\\n\\nThanks.\\n\\nHere is the corrected code which uses \"sorted\" function of python for sorting the dictionary entries by their values.\\n\\n```python\\nfrom Bio import SeqIO\\nfrom collections import defaultdict, OrderedDict\\n\\nmegascaffold_dict = defaultdict(list)\\nfor record in SeqIO.parse(\"megascaffolds.fasta\", \"fasta\"):\\n    megascaffold_dict[record.id] = record.seq\\n\\ngene_sequences = defaultdict(list)\\nwith open(\"megascaffold_coordinates.gff\") as f:\\n    for line in f:\\n        values = line.strip().split(\"\\\\t\")\\n        contig = values[0]\\n        start = int(values[3]) - 1\\n        end = int(values[4])\\n        gene_id = values[8].split(\"=\")[1]\\n        gene_seq = megascaffold_dict[contig][start:end]\\n        gene_sequences[contig].append((gene_id, gene_seq))\\n\\nseq_count = 1\\nfor contig, values in gene_sequences.items():\\n    for index, (gene_id, sequence) in enumerate(values):\\n        with open(f\"sequence_{seq_count}.fasta\", \"w\") as f:\\n            f.write(f\">{gene_id}\\\\n{sequence}\\\\n\")\\n        seq_count+=1\\n```\\n\\nHowever, in the above code also - I am still not correctly considering intergenic breakpoints. I am simply extracting sequences according the coordinates given in the GFF file. How can intergenic breakpoints be correctly considered.? In other words, how can scaffolds be broken at intergenic regions for writing sequences to files.. Following is the modified code which attempts to correct this:\\n\\n```python\\nfrom Bio import SeqIO\\nfrom collections import defaultdict, OrderedDict\\n\\nmegascaffold_dict = defaultdict(list)\\nfor record in SeqIO.parse(\"megascaffolds.fasta\", \"fasta\"):\\n    megascaffold_dict[record.id] = record.seq\\n\\ngene_sequences = defaultdict(list)\\nwith open(\"megascaffold_coordinates.gff\") as f:\\n    contig = \\'\\'\\n    previous_end = 0\\n    for line in f:\\n        values = line.strip().split(\"\\\\t\")\\n        curr_contig = values[0]\\n        start = int(values[3]) - 1\\n        end = int(values[4])\\n        gene_id = values[8].split(\"=\")[1]\\n        if contig!=curr_contig:\\n            contig = curr_contig\\n            previous_end = 0\\n        # intergene_seq = \\'\\'\\n        if previous_end==0:\\n            gene_start=0\\n        else:\\n            gene_start = previous_end+1\\n        # intergene_seq = megascaffold_dict[contig][gene_start:start-1]\\n        gene_seq = megascaffold_dict[contig][start:end]\\n        # gene_sequences[contig].append((gene_id, gene_seq, intergene_seq))\\n        gene_sequences[contig].append((gene_id, gene_seq))\\n        previous_end = end\\n\\nseq_count = 1\\nfor contig, values in gene_sequences.items():\\n    for index, (gene_id, sequence) in enumerate(values):\\n        with open(f\"sequence_{seq_count}.fasta\", \"w\") as f:\\n            f.write(f\">{gene_id}\\\\n{sequence}\\\\n\")\\n        seq_count+=1\\n```\\n\\nHowever, the above code also has issues with respect correctness of breakpoints.. Could anbody suggest any corrected code which is doing this task of breaking scaffolds whenever there are breaks in the genes.?\\n\\nNote:\\n1. There is no need for processing of intergenic breakpoints sequences.\\n\\n2. Here is the revised code according to the specifications provided below:\\n\\n```python\\nfrom Bio import SeqIO\\nfrom collections import defaultdict, OrderedDict\\n\\nmegascaffold_dict = defaultdict(list)\\nfor record in SeqIO.parse(\"megascaffolds.fasta\", \"fasta\"):\\n    megascaffold_dict[record.id] = record.seq\\n\\n# anticipate what should be the right coordinate\\ngene_sequences = defaultdict(list)\\nwith open(\"megascaffold_coordinates.gff\") as f:\\n    contig = \\'\\'\\n    previous_end = 0\\n    for line in f:\\n        values = line.strip().split(\"\\\\t\")\\n        curr_contig = values[0]\\n        start = int(values[3]) - 1\\n        end = int(values[4])\\n        gene_id = values[8].split(\"=\")[1]\\n        if contig!=curr_contig:\\n            if previous_end!=0:\\n                last_gene_seq = megascaffold_dict[contig][previous_end:]\\n                gene_sequences[contig].append((f\"{contig}_{len(gene_sequences[contig])}\", last_gene_seq))\\n            contig = curr_contig\\n            previous_end = 0\\n            if start!=0:\\n                first_gene_seq = megascaffold_dict[contig][0:start]\\n                gene_sequences[contig].append((f\"{contig}_{len(gene_sequences[contig])}\", first_gene_seq))\\n        elif previous_end!=0 and previous_end!=end:\\n            if start> previous_end+1:\\n                intergene_seq = megascaffold_dict[contig][previous_end+1:start]\\n                gene_sequences[contig].append((f\"{contig}_{len(gene_sequences[contig])}\", intergene_seq))\\n            elif start < previous_end+1:\\n                print(curr_contig, values[2], start, end, \"Error condition\")\\n        gene_seq = megascaffold_dict[contig][start:end]\\n        gene_sequences[contig].append((gene_id, gene_seq))\\n        previous_end = end\\n    # append the last gene\\n    if previous_end!=len(megascaffold_dict[curr_contig]):\\n        last_gene_seq = megascaffold_dict[curr_contig][previous_end:]\\n        gene_sequences[curr_contig].append((f\"{curr_contig}_{',\n",
       "   'role': 'user'}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 78/78 [00:00<00:00, 88.77ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:50<00:00, 50.77s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/hqfx/Skywork-Reward-Preference-80K-v0.2/commit/8a1f0bfb41ae0e1a28fdd89493b94a1a7b5e0d66', commit_message='Upload dataset', commit_description='', oid='8a1f0bfb41ae0e1a28fdd89493b94a1a7b5e0d66', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/hqfx/Skywork-Reward-Preference-80K-v0.2', endpoint='https://huggingface.co', repo_type='dataset', repo_id='hqfx/Skywork-Reward-Preference-80K-v0.2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_ds.push_to_hub(\"hqfx/Skywork-Reward-Preference-80K-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
