# Qwen3 Tool Call Server

åŸºäº FastAPI å’Œ vLLM å®ç°çš„ Qwen2.5 å’Œ Qwen3 LLM æœåŠ¡å™¨ï¼Œæä¾›ä¸ OpenAI API å®Œå…¨å…¼å®¹çš„ tool call åŠŸèƒ½ï¼Œæ”¯æŒå®Œæ•´çš„ tool choice å’Œ structured outputã€‚

## ç‰¹æ€§

- ğŸš€ åŸºäº FastAPI å’Œ vLLM çš„é«˜æ€§èƒ½å®ç°
- ğŸ”§ å®Œæ•´çš„å·¥å…·è°ƒç”¨ï¼ˆTool Callsï¼‰æ”¯æŒ
- ğŸŒŠ æ”¯æŒæµå¼è¾“å‡ºå’Œéæµå¼è¾“å‡º
- ğŸ§  æ”¯æŒ Qwen3 æ¨¡å‹çš„ reasoning åŠŸèƒ½
- âš¡ å¼‚æ­¥å¤„ç†ï¼Œé«˜æ€§èƒ½å“åº”
- ğŸ¯ å®Œå…¨å…¼å®¹ OpenAI API è§„èŒƒ

## å·¥å…·è°ƒç”¨ï¼ˆTool Callsï¼‰åŠŸèƒ½

### æ ¸å¿ƒç‰¹æ€§

- **å®Œæ•´çš„ Tool Choice æ”¯æŒ**
  - `auto`: è‡ªåŠ¨é€‰æ‹©å·¥å…·
  - `none`: ç¦ç”¨å·¥å…·è°ƒç”¨
  - `required`: å¼ºåˆ¶ä½¿ç”¨å·¥å…·
  - æŒ‡å®šå…·ä½“å·¥å…·åç§°

- **å¹¶è¡Œå·¥å…·è°ƒç”¨**
  - æ”¯æŒå¤šä¸ªå·¥å…·åŒæ—¶è°ƒç”¨
  - ä¿æŒè¾“å‡ºæ ¼å¼çš„ä¸¥æ ¼ä¸€è‡´æ€§

- **Structured Output**
  - å®Œå…¨æ”¯æŒ OpenAI çš„ strict æ¨¡å¼
  - åœ¨å¹¶è¡Œå·¥å…·è°ƒç”¨åœºæ™¯ä¸‹ä»ä¿æŒä¸¥æ ¼è¾“å‡ºæ ¼å¼
  - è¶…è¶Š OpenAI å®˜æ–¹å®ç°çš„é™åˆ¶ï¼ˆæ¯”å¦‚[å¹¶è¡Œå·¥å…·è°ƒç”¨åœºæ™¯ä¸‹ä¸èƒ½å¼€å¯ strict æ¨¡å¼](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling?api-mode=responses#:~:text=Note%3A%20Currently%2C%20if%20the%20model%20calls%20multiple%20functions%20in%20one%20turn%20then%20strict%20mode%20will%20be%20disabled%20for%20those%20calls.)ï¼‰

- **Qwen3 ç‰¹æ®ŠåŠŸèƒ½**
  - ä¸ºä¿æŒä¸ OpenAI API çš„æ¥å£ä¸€è‡´æ€§ï¼Œé€šè¿‡ `reasoning_effort` å‚æ•°å¯ç”¨ reasoning åŠŸèƒ½ï¼ˆä¼ ä»»æ„å€¼å‡å¯ï¼‰

## å®‰è£…

```bash
# å®‰è£…ä¾èµ–
uv sync

# å¯åŠ¨æœåŠ¡å™¨
bash run.sh
```

## ä½¿ç”¨æ–¹æ³•

### API ä½¿ç”¨ç¤ºä¾‹

```python
import openai

client = openai.OpenAI(
    base_url="http://localhost:8000",
    api_key="not-needed"
)

# æ™®é€šèŠå¤©
response = client.chat.completions.create(
    model="qwen",
    messages=[
        {"role": "user", "content": "ä½ å¥½"}
    ]
)

# ä½¿ç”¨å·¥å…·è°ƒç”¨
response = client.chat.completions.create(
    model="qwen",
    messages=[
        {"role": "user", "content": "æŸ¥è¯¢å¤©æ°”"}
    ],
    tools=[{
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {
                        "type": "string",
                        "description": "åŸå¸‚åç§°"
                    }
                },
                "required": ["city"]
            }
        }
    }]
)

# å¯ç”¨ Qwen3 çš„ reasoning åŠŸèƒ½ï¼Œä¸ tool call å…¼å®¹
response = client.chat.completions.create(
    model="qwen",
    messages=[
        {"role": "user", "content": "åˆ†æè¿™ä¸ªé—®é¢˜"}
    ],
    reasoning_effort="low"  # ä»»æ„å€¼å‡å¯
)
```

## æŠ€æœ¯æ¶æ„

- **Web æ¡†æ¶**: FastAPI
- **æ¨ç†å¼•æ“**: vLLM
- **è¯­æ³•æ§åˆ¶**: xgrammar
- **å¼‚æ­¥å¤„ç†**: asyncio
- **æ¨¡å‹æ”¯æŒ**: Qwen2.5/Qwen3 ç³»åˆ—æ¨¡å‹